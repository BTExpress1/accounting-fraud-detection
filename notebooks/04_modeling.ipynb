{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec2fe34f-4d03-4dea-9e16-6c0364791fe6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" align=center><h1>Accounting Fraud Detection Modeling</h1></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78668e0-a832-404c-b07b-88ffe39ff3a7",
   "metadata": {},
   "source": [
    "## <div class=\"alert alert-block alert-info\" ><h1>Imports</h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa49e72-3af5-426b-8c9b-7d817e00f9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import CatBoostClassifier\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "#Start a timer to check the execution time of the notebook.\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ab7b9-8677-4e38-b7f4-8e1bf4d7cc86",
   "metadata": {},
   "source": [
    "## <div class=\"alert alert-block alert-info\" ><h1>Function Definitions</h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c46954-9795-4ebb-ad2d-3681e3a2fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(learning_rate=0.001, dropout_rate=0.3, neurons=128):\n",
    "    \"\"\"\n",
    "    Build and compile a deep neural network with 3 hidden layers using LeakyReLU activations.\n",
    "\n",
    "    Parameters:\n",
    "    - learning_rate (float): Learning rate for the Adam optimizer.\n",
    "    - dropout_rate (float): Dropout rate to reduce overfitting.\n",
    "    - neurons (int): Number of neurons in the first hidden layer. Subsequent layers scale down.\n",
    "\n",
    "    Returns:\n",
    "    - model (Sequential): Compiled Keras model ready for training.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # First hidden layer: full neuron count with LeakyReLU and Dropout\n",
    "    model.add(Dense(neurons, input_shape=(X_train_scaled.shape[1],)))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Second hidden layer: half the neurons\n",
    "    model.add(Dense(neurons // 2))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Third hidden layer: quarter the neurons\n",
    "    model.add(Dense(neurons // 4))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output layer: binary classification with sigmoid\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile model with Adam optimizer and AUC tracking\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['AUC']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872720a-65d0-44e4-abd7-5bec43f5dec8",
   "metadata": {},
   "source": [
    "## <div class=\"alert alert-info\"><h1>Load the Models and the Data</h1></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d0a06-da14-4fd7-9ac5-ee6deb515f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "modelpath = \"../models\"\n",
    "datapath = \"../data\"\n",
    "\n",
    "# Load pre-fit ColumnTransformer\n",
    "scaler = joblib.load(os.path.join(modelpath,\"column_scaler.pkl\"))\n",
    "\n",
    "# Load models\n",
    "catboost_model = joblib.load(os.path.join(modelpath, \"catboost_model.pkl\"))\n",
    "dnn_model = load_model(os.path.join(modelpath, \"dnn_model.keras\"))\n",
    "\n",
    "# Load metadata\n",
    "with open(os.path.join(modelpath, \"catboost_model_meta.json\")) as f:\n",
    "    catboost_metadata = json.load(f)\n",
    "\n",
    "with open(os.path.join(modelpath, \"dnn_model_meta.json\")) as f:\n",
    "    dnn_metadata = json.load(f)\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(os.path.join(datapath, \"fraud_data_eda.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d145c3-f145-4b22-9c9c-d47186b3f242",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">We are tuning the models starting with CatBoost.<br>\n",
    "Before tuning, we will load the results from the baseline model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df87f91d-e62d-49d2-b453-4501cbf8115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target\n",
    "features = catboost_metadata[\"features\"]\n",
    "X = df[features]\n",
    "y = df[\"misstate\"]\n",
    "\n",
    "# 80/20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b851c8-d328-46d4-b81b-507bdde8bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply loaded scaler to train and test train data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Evaluate saved CatBoost model\n",
    "saved_pred = catboost_model.predict(X_test_scaled)\n",
    "saved_proba = catboost_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"üì¶ Saved CatBoost Model\")\n",
    "print(f\"Accuracy:     {accuracy_score(y_test, saved_pred):.4f}\")\n",
    "print(f\"F1 Score:     {f1_score(y_test, saved_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, saved_proba):.4f}\")\n",
    "print(classification_report(y_test, saved_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5e8e16-55d7-49e6-8878-26e0c5c7888d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">We will tune CatBoost model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1e6b93-d854-4731-b732-e6b7072eb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# Use in CatBoost\n",
    "tuned_catboost_scaled = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    eval_metric='AUC',\n",
    "    class_weights=class_weights,\n",
    "    iterations=530,\n",
    "    depth=6,\n",
    "    learning_rate=0.03837,\n",
    "    l2_leaf_reg=3.296,\n",
    "    border_count=114\n",
    ")\n",
    "\n",
    "tuned_catboost_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate on scaled test set\n",
    "y_pred = tuned_catboost_scaled.predict(X_test_scaled)\n",
    "y_proba = tuned_catboost_scaled.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"üì¶ Tuned CatBoost Model\")\n",
    "print(f\"Accuracy:     {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score:     {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f3abcd-8361-4389-9f95-484c4e44b5c3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Our tuned model significantly outperformed the baseline. \n",
    "Time for some cross-validation.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9554fd-0ae2-4b93-a024-df895f31765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 5  # cross-validation folds for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e00b4-881b-46d9-b3bf-4294d7aee747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    \"iterations\": randint(200, 1000),\n",
    "    \"depth\": randint(4, 8),\n",
    "    \"learning_rate\": uniform(0.005, 0.1),\n",
    "    \"l2_leaf_reg\": uniform(1, 5),\n",
    "    \"border_count\": randint(32, 128)\n",
    "}\n",
    "\n",
    "# Instantiate base model\n",
    "catboost_base = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    random_state=42,\n",
    "    eval_metric=\"AUC\",\n",
    "    class_weights=compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train).tolist()\n",
    ")\n",
    "\n",
    "# Randomized Search\n",
    "catboost_random_search = RandomizedSearchCV(\n",
    "    estimator=catboost_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=CV,\n",
    "    scoring=\"roc_auc\",\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run search\n",
    "#catboost_random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "#best_catboost = catboost_random_search.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "#y_pred = best_catboost.predict(X_test)\n",
    "#y_proba = best_catboost.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#print(\"üîç Tuned CatBoost\")\n",
    "#print(\"Best Params:\", catboost_random_search.best_params_)\n",
    "#print(\"ROC AUC:\", roc_auc_score(y_test, y_proba))\n",
    "#print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894718ee-78b7-426a-9363-a737aee37caa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">We will now tune our DNN model.<br>\n",
    "Before tuning, we will load the results from the baseline model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830808c0-8e3e-4d18-b421-39f122e2a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate saved CatBoost model\n",
    "saved_dnn_proba = dnn_model.predict(X_test_scaled)\n",
    "saved_dnn_pred = (saved_dnn_proba > 0.5).astype(int)\n",
    "\n",
    "\n",
    "print(\"üì¶ Saved DNN Model\")\n",
    "print(f\"Accuracy:     {accuracy_score(y_test, saved_dnn_pred):.4f}\")\n",
    "print(f\"F1 Score:     {f1_score(y_test, saved_dnn_pred):.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, saved_dnn_proba):.4f}\")\n",
    "print(classification_report(y_test, saved_dnn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb003df-1f13-4afb-8cea-c06b3aaaaa0c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">Time to perform hyperparameter tuning on the DNN model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f66b2-b85e-4335-b54e-a3e41ac433a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifier\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_model,  \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "# Define hyperparameter space\n",
    "param_dist = {\n",
    "    \"batch_size\": [32, 64, 128],\n",
    "    \"epochs\": [30, 50],\n",
    "    \"model__learning_rate\": uniform(1e-4, 9e-4),\n",
    "    \"model__dropout_rate\": uniform(0.2, 0.3),\n",
    "    \"model__neurons\": [64, 128, 256]\n",
    "}\n",
    "\n",
    "dnn_random_search = RandomizedSearchCV(\n",
    "    estimator=keras_clf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='roc_auc',\n",
    "    cv=CV,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "dnn_random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_dnn = dnn_random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c06f81-ab01-4a4c-a624-ad6ca345a47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Post-training prediction and threshold evaluation\n",
    "# Safe prediction with scikeras wrapper\n",
    "y_proba = best_dnn.model_.predict(X_test_scaled).ravel()\n",
    "\n",
    "threshold = 0.5\n",
    "# Default threshold\n",
    "print(\"Thresholds: \", threshold)\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "print(f\"Accuracy:     {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score:     {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC:      {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "threshold = 0.3\n",
    "print(\"\\nThresholds: \", threshold)\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "print(f\"Accuracy:     {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"F1 Score:     {f1_score(y_test, y_pred):.4f}\")\n",
    "print(f\"ROC AUC:      {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c8cd6-2c84-4dda-a55c-7116db5f49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [0.05, 0.03, 0.02, 0.01]:\n",
    "    print(f\"\\nThreshold: {t}\")\n",
    "    y_pred = (y_proba >= t).astype(int)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fca1e-56ae-45b8-bdb3-d2c62cd7e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_proba, bins=50)\n",
    "plt.title(\"Predicted probabilities\")\n",
    "print(\"DNN Best Params\", dnn_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a588c3b3-26c7-4fbe-9c9e-ec1c2e2054ee",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4CAF50; padding: 16px; border-radius: 8px; background-color: #F9FFFB; font-family: sans-serif; font-size: 15px\">\n",
    "  <strong>üí° Tuning Strategy Note:</strong><br><br>\n",
    "  Since we used <code>RandomizedSearchCV</code> with <code>cv=5</code> to broadly explore the hyperparameter space, we can now use <code>GridSearchCV</code> with <code>cv=3</code> for fine-tuning.<br><br>\n",
    "\n",
    "  <ul>\n",
    "    <li><strong>RandomizedSearchCV (cv=5):</strong> best for wide, randomized search with higher confidence in initial rankings.</li>\n",
    "    <li><strong>GridSearchCV (cv=3):</strong> faster when narrowing in on the optimal region around the best parameters.</li>\n",
    "  </ul>\n",
    "\n",
    "  This strategy gives us a good balance between performance and compute efficiency:\n",
    "  <ul>\n",
    "    <li>Use <code>GridSearchCV</code> to test smaller, precise hyperparameter ranges</li>\n",
    "    <li>Lowering to <code>cv=3</code> is acceptable at this stage, especially since folds are stratified</li>\n",
    "    <li>If two or more models are very close in performance, we can optionally rerun with <code>cv=5</code> on just the top configs</li>\n",
    "  </ul>\n",
    "\n",
    "  ‚úÖ This staged approach ensures reliable model selection without excessive training time.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b394a-93cb-4e89-8075-eaf80209fa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba944f0-fa75-4e2b-9856-95acf26f8c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the timer to check the execution time of the notebook.\n",
    "end_time = time.time()\n",
    "print(f\"Total execution time: {round(end_time - start_time, 2)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (fd-env)",
   "language": "python",
   "name": "fd-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
